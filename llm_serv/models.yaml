#
# This file contains the models that are available in the LLM service.
# It is used to populate the registry and the API.
# 

PROVIDERS:
  AWS:
    name: AWS
    config: {}
  AZURE:
    name: AZURE
    config: {}
  OPENAI:
    name: OPENAI
    config: {}
  GOOGLE:
    name: GOOGLE
    config: {}
  OPENROUTER:
    name: OPENROUTER
    config: {}
  TOGETHER:
    name: TOGETHER
    config: {}


MODELS:
  AZURE/gpt-4o:    
    internal_model_id: gpt-4o
    max_tokens: 128000
    max_output_tokens: 16000
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    price:
      input_price_per_1m_tokens: 0
      cached_input_price_per_1m_tokens: 0
      output_price_per_1m_tokens: 0
      reasoning_output_price_per_1m_tokens: 0      
    config: {}

  AZURE/gpt-4o-mini:
    internal_model_id: gpt-4o-mini
    max_tokens: 128000
    max_output_tokens: 16000
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    config: {}

  OPENAI/gpt-4.1-mini:
    internal_model_id: gpt-4.1-mini
    max_tokens: 1047576
    max_output_tokens: 32768
    capabilities:
      image_support: true
      document_support: true
      structured_output: true 
    price:
      input_price_per_1m_tokens: 0.4
      cached_input_price_per_1m_tokens: 0.1
      output_price_per_1m_tokens: 1.6
    config: {}

  OPENAI/gpt-4.1:
    internal_model_id: gpt-4.1
    max_tokens: 1047576
    max_output_tokens: 32768
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    price:
      input_price_per_1m_tokens: 2
      cached_input_price_per_1m_tokens: 0.5
      output_price_per_1m_tokens: 8
    config: {}

  OPENAI/gpt-5-mini:
    internal_model_id: gpt-5-mini
    max_tokens: 400000
    max_output_tokens: 128000
    fixed_temperature: true
    capabilities:
      image_support: true
      document_support: true
      structured_output: true 
    price:
      input_price_per_1m_tokens: 0.25
      cached_input_price_per_1m_tokens: 0.025
      output_price_per_1m_tokens: 2
    config: {}

  OPENAI/gpt-5:
    internal_model_id: gpt-5
    max_tokens: 128000
    max_output_tokens: 16384
    fixed_temperature: true
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    price:
      input_price_per_1m_tokens: 1.25
      cached_input_price_per_1m_tokens: 0.125
      output_price_per_1m_tokens: 10
    config: {}

  OPENAI/o4-mini:
    internal_model_id: o4-mini
    max_tokens: 200000
    max_output_tokens: 16000
    fixed_temperature: true
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    price:
      input_price_per_1m_tokens: 1.1
      cached_input_price_per_1m_tokens: 0.275
      output_price_per_1m_tokens: 4.4
    config: {}

  AWS/claude-3-5-sonnet:
    internal_model_id: anthropic.claude-3-5-sonnet-20240620-v1:0
    max_tokens: 200000
    max_output_tokens: 4096
    capabilities:
      image_support: false
      document_support: false
    config: {}
    
  AWS/eu-claude-3-5-sonnet:
    internal_model_id: eu.anthropic.claude-3-5-sonnet-20240620-v1:0
    max_tokens: 200000
    max_output_tokens: 4096
    capabilities:
      image_support: false
      document_support: false
    config: {}

  AWS/claude-3-haiku:
    internal_model_id: anthropic.claude-3-haiku-20240307-v1:0
    max_tokens: 200000
    max_output_tokens: 4096
    capabilities:
      image_support: true
      document_support: false
    config: {}

  GOOGLE/gemini-2.5-flash:
    internal_model_id: gemini-2.5-flash-preview-05-20
    max_tokens: 1047576
    max_output_tokens: 65535
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    config: {}

  OPENROUTER/deepseek-v3-free:
    internal_model_id: deepseek/deepseek-chat-v3-0324:free
    max_tokens: 128000
    max_output_tokens: 32768
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    config: {}
  
  OPENROUTER/deepseek-r1-free:
    internal_model_id: deepseek/deepseek-r1-0528:free
    max_tokens: 163840
    max_output_tokens: 32768
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    config: {}
  
  OPENROUTER/llama-4-maverick-free:
    internal_model_id: meta-llama/llama-4-maverick:free
    max_tokens: 128000
    max_output_tokens: 4028
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    config: {}

  GOOGLE/gemini-2.0-flash-exp:
    internal_model_id: google/gemini-2.0-flash-exp:free
    max_tokens: 1047576
    max_output_tokens: 65535
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    config: {}

  OPENAI/text-embedding-3-small:
    internal_model_id: text-embedding-3-small
    max_tokens: 8192
    max_output_tokens: 0
    capabilities:
      embedding: true
    price:
      input_price_per_1m_tokens: 0.02
      cached_input_price_per_1m_tokens: 0
      output_price_per_1m_tokens: 0
      reasoning_output_price_per_1m_tokens: 0
    config: {}

  OPENAI/text-embedding-3-large:
    internal_model_id: text-embedding-3-large
    max_tokens: 8192
    max_output_tokens: 0
    capabilities:
      embedding: true
    price:
      input_price_per_1m_tokens: 0.13
      cached_input_price_per_1m_tokens: 0
      output_price_per_1m_tokens: 0
      reasoning_output_price_per_1m_tokens: 0
    config: {}
    
  TOGETHER/Llama-3.2-3B-Instruct-Turbo:
    internal_model_id: meta-llama/Llama-3.2-3B-Instruct-Turbo
    max_tokens: 128000
    max_output_tokens: 4096
    capabilities:
      image_support: false
      document_support: false
      structured_output: true
  # prices are mocked
    price:
      input_price_per_1m_tokens: 0.06
      cached_input_price_per_1m_tokens: 0.06
      output_price_per_1m_tokens: 0.06
      reasoning_output_price_per_1m_tokens: 0.06
    config: {}
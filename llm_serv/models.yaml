#
# This file contains the models that are available in the LLM service.
# It is used to populate the registry and the API.
# 

PROVIDERS:
  AWS:
    name: AWS
    config: {}
  AZURE:
    name: AZURE
    config: {}
  OPENAI:
    name: OPENAI
    config: {}
  GOOGLE:
    name: GOOGLE
    config: {}
  OPENROUTER:
    name: OPENROUTER
    config: {}
  TOGETHER:
    name: TOGETHER
    config: {}


MODELS:
  AZURE/gpt-4o:    
    internal_model_id: gpt-4o
    max_tokens: 128000
    max_output_tokens: 16000
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    price:
      input_price_per_1m_tokens: 0
      cached_input_price_per_1m_tokens: 0
      output_price_per_1m_tokens: 0
      reasoning_output_price_per_1m_tokens: 0      
    config: {}

  AZURE/gpt-4o-mini:
    internal_model_id: gpt-4o-mini
    max_tokens: 128000
    max_output_tokens: 16000
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    config: {}

  OPENAI/gpt-4.1-mini:
    internal_model_id: gpt-4.1-mini
    max_tokens: 1047576
    max_output_tokens: 32768
    capabilities:
      image_support: true
      document_support: true
      structured_output: true 
    price:
      input_price_per_1m_tokens: 0.4
      cached_input_price_per_1m_tokens: 0.1
      output_price_per_1m_tokens: 1.6
    config: {}

  OPENAI/gpt-4.1:
    internal_model_id: gpt-4.1
    max_tokens: 1047576
    max_output_tokens: 32768
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    price:
      input_price_per_1m_tokens: 2
      cached_input_price_per_1m_tokens: 0.5
      output_price_per_1m_tokens: 8
    config: {}

  OPENAI/gpt-5-mini:
    internal_model_id: gpt-5-mini
    max_tokens: 400000
    max_output_tokens: 128000
    fixed_temperature: true
    capabilities:
      image_support: true
      document_support: true
      structured_output: true 
    price:
      input_price_per_1m_tokens: 0.25
      cached_input_price_per_1m_tokens: 0.025
      output_price_per_1m_tokens: 2
    config: {}

  OPENAI/gpt-5:
    internal_model_id: gpt-5
    max_tokens: 128000
    max_output_tokens: 16384
    fixed_temperature: true
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    price:
      input_price_per_1m_tokens: 1.25
      cached_input_price_per_1m_tokens: 0.125
      output_price_per_1m_tokens: 10
    config: {}

  OPENAI/o4-mini:
    internal_model_id: o4-mini
    max_tokens: 200000
    max_output_tokens: 16000
    fixed_temperature: true
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    price:
      input_price_per_1m_tokens: 1.1
      cached_input_price_per_1m_tokens: 0.275
      output_price_per_1m_tokens: 4.4
    config: {}

  AWS/claude-3-5-sonnet:
    internal_model_id: anthropic.claude-3-5-sonnet-20240620-v1:0
    max_tokens: 200000
    max_output_tokens: 4096
    capabilities:
      image_support: false
      document_support: false
    config: {}
 
  GOOGLE/gemini-2.5-flash:
    internal_model_id: gemini-2.5-flash
    max_tokens: 1047576
    max_output_tokens: 65535
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    price:
      input_price_per_1m_tokens: 0.3
      cached_input_price_per_1m_tokens: 0.075
      output_price_per_1m_tokens: 2.5
      reasoning_output_price_per_1m_tokens: 2.5
    config: {}

  GOOGLE/gemini-2.5-flash-lite:
    internal_model_id: gemini-2.5-flash-lite
    max_tokens: 1048576
    max_output_tokens: 65536
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    price:
      input_price_per_1m_tokens: 0.1
      cached_input_price_per_1m_tokens: 0.025
      output_price_per_1m_tokens: 0.4
      reasoning_output_price_per_1m_tokens: 0.4
    config: {}

  GOOGLE/gemini-2.5-pro:
    internal_model_id: gemini-2.5-pro
    max_tokens: 1047576
    max_output_tokens: 65535
    capabilities:
      image_support: true
      caching: true
      function_calling: true
      code_execution: true
      thinking: true
      batch_mode: true      
      structured_output: true
    price:
      input_price_per_1m_tokens: 1.25
      cached_input_price_per_1m_tokens: 0.31
      output_price_per_1m_tokens: 10
      reasoning_output_price_per_1m_tokens: 10
    config: {}

  OPENROUTER/deepseek-v3-free:
    internal_model_id: deepseek/deepseek-chat-v3-0324:free
    max_tokens: 128000
    max_output_tokens: 32768
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    config: {}
  
  OPENROUTER/deepseek-r1-free:
    internal_model_id: deepseek/deepseek-r1-0528:free
    max_tokens: 163840
    max_output_tokens: 32768
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    config: {}
  
  OPENROUTER/llama-4-maverick-free:
    internal_model_id: meta-llama/llama-4-maverick:free
    max_tokens: 128000
    max_output_tokens: 4028
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    config: {}

  GOOGLE/gemini-2.0-flash-exp:
    internal_model_id: google/gemini-2.0-flash-exp:free
    max_tokens: 1047576
    max_output_tokens: 65535
    capabilities:
      image_support: true
      document_support: true
      structured_output: true
    config: {}

  OPENAI/text-embedding-3-small:
    internal_model_id: text-embedding-3-small
    max_tokens: 8192
    max_output_tokens: 0
    capabilities:
      embedding: true
    price:
      input_price_per_1m_tokens: 0.02
      cached_input_price_per_1m_tokens: 0
      output_price_per_1m_tokens: 0
      reasoning_output_price_per_1m_tokens: 0
    config: {}

  OPENAI/text-embedding-3-large:
    internal_model_id: text-embedding-3-large
    max_tokens: 8192
    max_output_tokens: 0
    capabilities:
      embedding: true
    price:
      input_price_per_1m_tokens: 0.13
      cached_input_price_per_1m_tokens: 0
      output_price_per_1m_tokens: 0
      reasoning_output_price_per_1m_tokens: 0
    config: {}
    
  # https://www.together.ai/models/deepseek-v3-1
  TOGETHER/DeepSeek-V3.1:
    internal_model_id: deepseek-ai/DeepSeek-V3.1
    max_tokens: 128000
    max_output_tokens: 8000
    price:
      input_price_per_1m_tokens: 0.60      
      output_price_per_1m_tokens: 1.70
    config: {}

   # https://www.together.ai/models/deepseek-v3-1
  TOGETHER/DeepSeek-V3:
    internal_model_id: deepseek-ai/DeepSeek-V3
    max_tokens: 128000
    max_output_tokens: 8000
    price:
      input_price_per_1m_tokens: 0.60      
      output_price_per_1m_tokens: 1.70
    config: {}
  
  # https://www.together.ai/models/deepseek-v3-1
  TOGETHER/DeepSeek-V3.1-thinking:
    internal_model_id: deepseek-ai/DeepSeek-V3.1
    max_tokens: 128000
    max_output_tokens: 32768
    capabilities:    
      thinking: true
    price:
      input_price_per_1m_tokens: 0.60      
      output_price_per_1m_tokens: 1.70      
    config: {}

  # https://www.together.ai/models/deepseek-r1  quantized FP8
  TOGETHER/DeepSeek-R1:
    internal_model_id: deepseek-ai/DeepSeek-R1
    max_tokens: 128000
    max_output_tokens: 8096
    capabilities:
      image_support: false
      document_support: false
      structured_output: true
    price:
      input_price_per_1m_tokens: 3
      output_price_per_1m_tokens: 7
    config: {}

  # https://www.together.ai/models/gpt-oss-120b FP4
  TOGETHER/gpt-oss-120b-fp4-low-reasoning:
    internal_model_id: openai/gpt-oss-120b
    max_tokens: 128000
    max_output_tokens: 8000
    capabilities:
      structured_output: true
      reasoning_effort: low
    price:
      input_price_per_1m_tokens: 0.15
      output_price_per_1m_tokens: 0.6      

  TOGETHER/gpt-oss-120b-fp4-medium-reasoning:
    internal_model_id: openai/gpt-oss-120b
    max_tokens: 128000
    max_output_tokens: 8000
    capabilities:
      structured_output: true
      reasoning_effort: medium
    price:
      input_price_per_1m_tokens: 0.15
      output_price_per_1m_tokens: 0.6

  # https://www.together.ai/models/qwen3-235b-a22b-fp8-tput fp8
  TOGETHER/Qwen3-235B-A22B-fp8-tput-throughput:
    internal_model_id: Qwen/Qwen3-235B-A22B-fp8-tput
    max_tokens: 40000
    max_output_tokens: 15000
    capabilities:
      structured_output: true
    price:
      input_price_per_1m_tokens: 0.2
      output_price_per_1m_tokens: 0.6

  # https://www.together.ai/models/qwen3-235b-a22b-instruct-2507-fp8 fp8
  TOGETHER/Qwen3-235B-A22B-Instruct-2507-tput:
    internal_model_id: Qwen/Qwen3-235B-A22B-Instruct-2507-tput
    max_tokens: 262000
    max_output_tokens: 15000
    capabilities:
      structured_output: true
    price:
      input_price_per_1m_tokens: 0.2
      output_price_per_1m_tokens: 0.6

  TOGETHER/Meta-Llama-3.1-8B-Instruct-Turbo:
    internal_model_id: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
    max_tokens: 128000
    max_output_tokens: 8000
    capabilities:
      structured_output: true
    price:
      input_price_per_1m_tokens: 0.2
      output_price_per_1m_tokens: 0.6